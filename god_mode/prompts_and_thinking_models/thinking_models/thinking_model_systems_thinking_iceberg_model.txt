Iceberg Model
SYSTEMS THINKING
Uncover root causes of events by looking at hidden levels of abstractions.
Addressing problems only on their event level is often not enough. The real causes are often hidden from plain sight.

Iceberg model is a tool that allows you to shift your perspective and see beyond the immediate events that everyone notices. It helps you to uncover root causes of why those events happen. That's possible by looking at deeper levels of abstraction within the system that are not immediately obvious.

How to use it
Iceberg model consists of four levels:

Events
Patterns
Structures
Mental models
Iceberg Model – Events > Patterns > Structures > Mental models. Author: Justin Farrugia
Example of an iceberg model by Justin Farrugia

Looking below individual events, you can see trends over time—patterns. They are the clue for understanding the system structures that are behind those patterns. Structures are the relationships and feedback loops inside a system. These structures are in turn based on the underlying mental models of people.

Events and patterns show you what is happening. Structures and mental models tell you why it's happening.

The deeper you can go in the iceberg, the more leverage you'll have.

Investigate all four levels
Here are some questions to help you understand each level within a certain problem or situation.

Events:

What is happening right now?
Patterns:

What has been happening over time? What are the trends? 
Structures:

What's influencing these patterns?
Where are the connections between patterns?
Mental models:

What values, beliefs or assumptions shape the system?
It's important to note that answering these questions will likely require some research and digging. Especially when it comes to the mental models which are hard to document, let alone see in plain sight.

Example of the Iceberg model by Justin Farrugia

Example
Let's look at a real-world example to better understand how the iceberg model works.

Suppose there are a couple of bugs in the feature your product team just released. That's a single event. Your instinct might be to react to it and start fixing them. That's obviously not enough if you want to prevent it from happening in the future.

If you look back in time, you see that every released feature comes with several bugs. That's a pattern. Digging deeper, you find that teams don't plan for testing before releasing a feature. The QA only happens after a release. Teams also typically have tight deadlines to ship a feature. These are structures of the system.

Investigating further, you discover that teams value shipping on time over the quality of their work. The tight deadlines are imposed by managers and teams believe it's not their place to push back.

As you can see, by looking beyond immediate events, you are able to find a root cause of a problem. You now have much more leverage for solving the problem.

Template for Iceberg model
I created a handy worksheet to help you put this tool into practice. It comes with a simple how-to guide including an example. Get it in a bundle with 9 other useful tools:














verything is connected. A child randomly kicks the elephant on the mobile hanging over her crib, and the other members of the aerial zoo shift their positions as well. An acorn drops in a quiet pond, and ripples move out over the whole surface. A butterfly flaps its wings in Brazil, and a tornado sweeps down the plains in Oklahoma.

These and other metaphors are often used to help explain systems theory, and they do so effectively — to a point. Many people can intellectually grasp the idea of interconnections in our world and the importance of taking a holistic perspective. But for some, the concept seems so easy to understand that they miss its value. For them, having a metaphorical understanding of systems thinking does not necessarily lead to action or to an integration of the concepts into everyday practice.

Nevertheless, it’s not necessary to have a deep understanding of systems theory in order to use it to influence institutional behavior. What is crucial is to connect some of the elements of systems thinking directly to proposed actions. In this article, I suggest how organizations might apply four models to make the transition from thinking to action. The iceberg metaphor helps to probe the underlying causes of events and patterns. The force field analysis provides a visual means of understanding the factors that keep organizations in “quasi-equilibrium” and the issues involved in any change process. The spidergram emphasizes linkages within a given system. Finally, behavior over time graphs draw attention to the long-range effects of organizational efforts.

The Iceberg (It’s bigger than you think!)
The iceberg is one of the most frequently used models to explain systems thinking (see “The Iceberg”). Thanks to movies like “Titanic,” many people recognize that most of an iceberg sits hidden beneath the water; that is, out of sight.

Different authors present the iceberg model as having from three to six levels; we’ll use a four-level model here.

In the iceberg model, the piece of the structure that appears above the surface represents a single “event.” A young woman arrives an hour late for work after dropping off her young child at a nursery. Her supervisor is understanding — this time. Just below the surface, a deeper level of examination reveals patterns of events, or “trends.” The young mother is late on the same day a week later. We might ask, in this case or any similar situation, whether these two events are unique or if a pattern of behavior is beginning to emerge.

It’s not necessary to have a deep understanding of systems theory in order to use it to influence institutional behavior.

Submerged below the level of the trend is the “structure,” the foundation that supports and creates the behaviors higher up in the pyramid. In the case of the working mother, is she late every week because the organization has strict policies about when staffers need to be in the office — policies that don’t take into account when daycare facilities open their doors in the morning? Would a more effective policy be one that allows employees to work flexible hours or dial in from home on some days? In organizations, the structure is often determined by its policies and procedures.

THE ICEBERG
THE ICEBERG
Each level down the iceberg offers a deeper understanding of the system being examined as well as increased leverage for changing it.


At the next level down, our “mental models” — and those of the people who came before us — affect the structures we put in place and the way we understand the top parts of the iceberg. Is the company founded on a sense of trust for its employees, or does management view itself as needing to monitor workers’ hours to make sure they put in what they’re being paid for? Is “face time” more important than productivity? These attitudes affect the company’s policies and ultimately how it treats all employees, including those with small children.

Each level down the iceberg offers a deeper understanding of the system being examined as well as increased leverage for changing it. Consider, for example, the response of many communities across the U. S. to the events of September 11. Immediately following the tragedy, various groups sponsored events embracing immigrants, with participants singing “We Are the World” and taking part in other heart-warming efforts to reach out to others in a time of national pain and anguish. These events were nice, but of little long-term significance. If the planners had applied the iceberg model to the process, they might have begun by asking simply, “Will we do this again? Should it become an annual event?”

Other questions lead deeper into the model. How do we keep this issue in people’s vision throughout the year? Are there other ways that we might integrate new immigrants into our community? How might we link “native” families to those who are new? And, ultimately, what can we do to open the minds of Americans to see the benefits of the diversity provided by the influx of immigrants? Such exploration might lead to a revival of workshops in cross-cultural understanding such as those brought forth by local ecumenical councils during desegregation.

As shown here, groups can use the iceberg model to improve program planning and to integrate systems thinking into the process. Next time you are involved in event planning, ask yourself whether you are planning an event or a whole movement!

FORCE FIELD ANALYSIS
FORCE FIELD ANALYSIS


Force Field Analysis (I’m losing my balance!)
Another useful approach to getting deeper into a systems mode of thinking is the force field analysis attributed to Kurt Lewin (, “Resolving Social Conflicts,” Selected Papers on Group Dynamics, 1948). Force field analysis (FFA) is a well-known tool for examining change (see “Force Field Analysis”). It asks, “What forces are at play to increase the odds of a given change taking hold, and what are the elements hindering that change?” This framework provides a rich systems perspective on an issue.

The concept is simple. At any given moment, an organization is in equilibrium; that is, there’s a balance between opposing forces. Without this balance, operations couldn’t move along at their normal pace. When a new idea to change the way the organization operates comes along, it threatens to disrupt the balance. But the forces that maintain the status quo usually make it difficult for change initiatives to take root. The FFA offers a useful way to illustrate this dynamic.

As an example, consider the issue of organizational paperwork. When the academic vice president in an institution of higher education proclaims, “We must simplify operations and eliminate as much unnecessary paperwork as possible,” you can hear the roar of approval from the faculty. But then the change does not happen.

Why? The FFA analysis can provide an understanding of the system as it exists and why there is resistance to change.

Imagine the forces that oppose such a change. For instance, in an attempt to ensure that departments spend certain funds properly, the institutional effectiveness office creates a form requiring that someone from its staff sign off on expenditures of more than $100 from those funds. The graduate college believes that another college in the university is not following standards, so they insist on receiving duplicates of all paperwork that involves graduate students. Department chairs, who have not received any training regarding institutional procedures, fail to follow some of the mandatory processes and lose the trust of the vice president, who then insists on signing off on all travel forms. And on it goes.

In these situations, the top manager often tries to force the change with further declarations and threats. Predictably, the use of strong-arm tactics frequently results in greater resistance.

A more productive way to approach the problem is by listing and examining the balancing forces that prevent the change from taking root (see the table below). Is an individual’s status within the university determined by how many decisions he or she must sign off on? If so, how can we change this reality? Are new faculty members adequately trained on proper completion of paperwork? If not, why? In what ways do various policies reinforce the status quo? How did those forces come about? What can be done to eliminate the forces of resistance or to redirect them in such a manner that they support the proposed change? Each question expands our understanding of the system and opens up possible methods of supporting the initiative.

Spidergram (Not Spider Man!)
Another metaphor for explaining systems thinking is that of a spider web. In The Web of Life (Anchor Books, 1996), Fritjof Capra uses the spider web as the central metaphor to describe the interconnections of all life on Earth. A disruption at one point in the web has an impact that reaches to all points, as it also does in human institutions.

SPIDERGRAM
SPIDERGRAM


Applying this systems metaphor to organizational issues is easy through the spidergram (see “Spidergram”). First, place the initiative, change, or process to be modified in the center of the web. Then draw threads outward, with blocks at the ends that represent anchoring points for the web. Identify, at each anchor, a unit or process within the organization that might be affected by the change. Stretch your mind to identify all possible anchors. Then, along each line connecting the center to an anchor, indicate the potential impact that the action might have on the anchor.

Consider, for example, an admissions unit in a hospital. The CEO believes that no one should have to stand in line for anything. The admissions staff is aware of and agrees with this perspective. They would also like to reduce their workload, so when budget time comes around, they ask for two additional positions to be created. From their perspective, this is the right thing to do.

Applying the spidergram to this issue involves placing the admissions unit’s request in the center of the web. What then are the anchor points? They might include the hospital budget; the other departments that would be affected by adding expense and capacity to the admissions unit, such as the records office and human resources; and customer satisfaction.

The next step is to note anticipated side effects of funding two more positions in admission on the anchor points. Will other departments requesting positions go without? Will the workload in the records office increase to the point where it begins to cause delays in patient services? Are there other means of resolving the issue, such as sending patients paperwork in advance to complete before coming to the hospital?

The spidergram will not provide an answer as to whether or not the hospital should support the admissions office’s request. It will, however, help identify the interconnections that exist and the potential impact of the proposal beyond the single unit or process involved. It is an extremely useful systems thinking strategy to help an organization see the “big picture” and to avoid sub-optimizing the whole in order to fulfill requests by units with strong and persistent advocates.

Behavior over Time Graphs (The long view)
Short-term thinking leads to event-level actions (as shown in the iceberg model). The number of surgeries in a given month, students enrolled in the fall semester, and quarterly profits are all examples of short-term thinking. If people do view those bits of data historically, they often do so only in relationship to the previous year’s numbers, and begin and end the examination with the question “Are we up?” And often, closely examining the numbers is a guise for searching for someone to blame for a decline!

A systems perspective encourages looking at more data points over a longer period and within a larger context than we’re used to doing. It involves analyzing relevant trends and other patterns that may be acting on the numbers we’re examining at the moment. The graphs may include both historical data and anticipated or desired future trends after a particular intervention. These graphs do not have to be precise, though they should be representative of actual or projected trends in order to be of value. If taken seriously, so-called behavior over time graphs can provide a means for understanding the flow of events and enhance discussion both of the past and the future (see “Behavior over Time Graph” on p. 9).

Take the example of a decline in enrollment numbers in a given department within a large university. The president sees the drop and, with great frustration, calls the provost: “What’s going on over there? Why aren’t the faculty doing their jobs?” The provost calls the dean, who phones the department chair. The chair reminds the dean that they agreed to raise standards for admission to the program in order to meet increasing state employment standards for graduates. Looking at long-term student enrollment patterns in similar situations might have led the administrators to understand that numbers frequently decline at first before enrollment begins to rise again. And doing so might have kept everyone’s blood pressure in check.

“Behavior over Time Graph” represents a small local business that had a tremendous launch, but then experienced lagging sales. When top managers considered the demographics of the individuals they catered to, they recognized that many of the older retirees who had created their initial success had left the state or died. To boost sales, they would need to consider marketing to a slightly younger crowd or even altering their product. Graphing trends in the rise or fall of multiple variables (enrollment and the local economy in higher education, sales and new product introductions in manufacturing, and so on) helps generate discussion, leading to hypotheses and deeper understanding of the trends as part of creating an overall strategy.

BEHAVIOR OVER TIME GRAPH
BEHAVIOR OVER TIME GRAPH


Back to Start
Busy executives who think that systems thinking is interesting but of limited value are missing an important tool for change. The best-laid plans can go astray if the whole system has not been considered. Administrators in every kind of organization can benefit from the use of these and other metaphors and models that build a deep understanding of the systems within which they work and live, and strengthen their actions toward continuous improvement.

















Visualizing the systems behind our designs
Tangible systems thinking that goes beyond buttons.
Justin Farrugia
UX Collective
Justin Farrugia

·
Follow

Published in
UX Collective

10 min read
·
Feb 25, 2020

Listen


Share


More


A button on the left which is what we see, and a complex casual loop diagram on the right which is what’s actually happening
Systems thinking is often heralded in different circles as a competency that’s worth investing in. Having a wider lens and being able to model the systems that influence inputs, outputs and the patterns of behavior for people using the products we build is how we can deliver real value.

Most product designers tend to default to design systems as a proxy for systems thinking. They’re not entirely wrong. The ecology around building design systems does require maintainers to think systematically. They need to deeply understand the core needs of the product team, to deliver reusable component libraries coupled with accompanying guidelines, processes, and documentation.

However, this doesn’t mean that building a design system is the only natural outcome of thinking in systems. Far from it.

Beyond buttons
As of writing, few people in history have had the surreal experience of being able to witness the Earth from space in person. Astronauts often recall the overwhelming experience they felt when looking at the fragile blue ball they called home. Their front row seats enabled them to see the world through a different lens, one where all life was interconnected and every system they’ve come to know was working in concert.

Astronomy author Frank White called this experience, ‘The Overview effect’.

An astronaut saying ‘Woah’ whilst looking at Earth,
Whilst not nearly as life-changing of an experience, zooming out from our narrowly focused product domains and realizing every design decision’s ripple effect in the ecosystem we operate in, can have a similar effect. Designing software often requires us to situate ourselves at both a macro and micro level. Yet, sometimes there’s a tendency to over-index on the latter at the expense of a broader set of goals.

As a result, we risk becoming distracted with the details when we can’t afford to do so. The tools, products and service experiences we’re shaping today are responsible for far more than just the daily metric movements relative to the bottom line. They inhabit already complex systems such as political landscapes or socioeconomic hierarchies and sometimes unconsciously introduce new dynamics that have outsized impacts.

We are surrounded by systems that we’ve directly or indirectly shaped or been a product of.

That being said we’ve done very little to represent any of them. By doing so we can peel back the layers and uncover patterns, boundaries, behaviors and even points of leverage where we can infer our influence. The good news is that we have an underdeveloped muscle which we ought to flex more often that can help us out.

Tools of the trade
We often picture systems in a linear fashion where A leads to B. Needless to say this is a reductive way of describing relationships and causality, as it overlooks the fact that each node may disrupt or restore the balance in uniquely different ways. In other words, systems are messy.

Linear Systems Thinking versus Loop Based Systems Thinking
Instead of A leading to B, it’s more likely you’ll find something like, A can cause B and C given a set of conditions, both of which reinforce D which restarts the cycle. Now trying to articulate all that through text isn’t exactly the best way to explain what’s actually going on. That’s where system diagramming can come in handy. Below are a few examples.

Behavior Over Time Graph
You’ve probably already seen this type of diagram being plotted somewhere on an office whiteboard. This graph helps us see patterns and interrelationships that emerge over a specific period of time. We can use it to observe how and why something is happening.

Let’s use something we’re all too familiar with as an example — product debt. Two things that we can use as variables in our graph are the cost of building features which keeps rising exponentially as the product matures, and customer value delivered which is inversely proportional due to fragmentation and debt that the team is spending time wrestling with.

A behaviour over time graph that indicates when a product team should address its mounting debt.
Despite ancillary efforts to revive that delivery curve from declining further, it most likely wouldn’t be enough to curb the overhead. The intersection point between the two curves signals the necessity for a cadence of refactoring or even a commitment towards building a design system.

Quadrant Matrix
This is another common diagram, that also has likely donned a few whiteboards. It is mainly used to represent the strength of relationships between several different items. You’ve likely seen it being used to chart the impact versus effort of doing something in a bid to inform the decision-making process.

A quadrant of usability issues with repetition versus impact
Let’s say you’ve finished up a moderated usability testing session and you’ve come away with a few insights. To start applying what you’ve learned you’ll need to rank your findings against a few different dimensions namely repetition and impact. Using a quadrant matrix will help you synthesize the raw data you’ve collected and visually make sense of what issues were the most severe and iron them out through iteration.

Iceberg Model
The iceberg model is a tool that can be used to show the four levels of abstraction within a specific setting that can allow us to uncover the root cause of why something is actually happening the way it is. It helps us go beyond the observable events that anyone can notice, and help us realize the patterns that might have contributed to those events, the structures that have influenced those patterns and the underlying mental models that keep those structures in place.

Often times when we try to address a problem, we do it on an event level which in turn leads to suboptimization. It’s not enough to swap things around, change information flow or incentives. You’ll need to expand the perception and shift mental models to have leverage and upend the system.

Let’s take a real-world example of a product team that’s trying to meet a deadline. An event would be that the team doesn’t ship in time. The natural tendency is to be reactive and start to find people to blame. Instead of playing the blame game start looking at the trends that might have led to this.

The Iceberg Model representing the Events, Patterns, Structures and Mental Models behind a product team missing a deadline.
A pattern might be looking at recurring evidence like the team’s collective track record and finding that three of the last five things they’ve worked on have had overrun dates. The structures that might be causing these patterns could be bandwidth issues with engineers and designers needing to context switch due to commitments outside the team.

What’s keeping this system in place is the mental model each team member holds, which might normalize the balancing act of being first responders instead of establishing a cadence coupled with some boundaries.

Reinforcing Feedback Loops
However intentional it might have been, you’ve probably designed a reinforcing feedback loop. As the name suggests, these kinds of loops have self-reinforcing behavior where the actions of one variable reinforce another. I’d be remiss to not mention the Hooked model as an example of a reinforcing loop that optimizes user stickiness and engagement.

The Hooked Model by Nir Eyal.
Unsurprisingly, reinforcing feedback loops are used and abused. Most consumer products with some kind of social component and a healthy network effect have reinforcing feedback loops baked into the fabric of the core experience. Products like TikTok have predictive models, computer vision and matrix factorization algorithms each built-in to perfect the content recommendation loop and have our attention.

TikTok’s reinforcing feedback loop.
Even though it has a cold start problem, after only a few seconds of watching and a series of swipes TikTok has collected enough data points and spun that loop so many times, that the content suddenly becomes unmissable. The diagram above illustrates this example.

Balancing Feedback Loops
Instead of creating a snowball effect, balancing feedback loops counter an input with an opposite output. These loops can correct an oversupply or undersupply, indicate that a plateau has been reached or restore the lost stability back to the system. Like reinforcing feedback loops however, the outcome of balancing feedback loops might not always lead to positive outcomes depending on prior inputs.

Some teams seem to jump the gun when it comes to bridging the gap between their customer success representatives and the customers. Access to an agent is either obscured by a messy navigation system or else it’s available at all times even when unnecessary. Both are examples of a balancing feedback loop.

The ramifications of introducing a chat bubble representing as a balancing feedback loop.
The former being the increase in customer frustration in trying to flag an issue by jumping through a few hoops which leads to an inevitable decrease in experiential and customer satisfaction measures. The latter shows a complete disregard for the time spent in answering repeatable queries which increases given there is no FAQ-like system in place which in turn leads to customer success agents availability decreasing, diminishing the likelihood of being a first responder for high-value accounts.

External Factors, Gaps, and Delays in Causal Loops
In the ever-increasing complexity of the systems we build towards, loops rarely ever have equally defined units of input or output. There are usually things that happen in between or outside of the model that have an effect. What better way to represent concepts like gaps and delays than an unpredictable complex landscape like healthcare, specifically the use of software in aiding care decisions.

Electronic Health Records or EHRs are real-time robust systems used in hospitals that contain the medical history of a patient. Their goal is to ultimately chip away at the mundanity of paperwork and enable a meaningful patient to physician interaction. If you zoom out far enough, the most basic loop you can make out is the one where the effects of introducing an EHR into a previously paper-run practice become visible.

Diagram of a reinforcing feedback loop that shows the effects of introducing an Electronic Health Record or EHR.
As can be seen in the diagram above, the impact of introducing an EHR into the mix has saved staff time which in turn has increased the patient treatment quality. As a result, the better the treatment quality, the more time will be saved in preventing adverse drug events or readmissions.

Diagram representing a delay within a causal loop.
Now that’s not going to happen overnight, the staff on hand needs to be gradually onboarded onto the new system and get familiar. That’s why this feedback loop will likely have delays which we can represent by marking the arc with a double line.

Diagram representing an external factor, in this case an update to the software.
Our feedback loop is still looking a bit too convenient. Let’s introduce another component, such as an update to the EHR software. That in itself might eat up some of that time the staff is saving since there might need to be retraining. That’s called an external factor. Gaps can also be another feature of causal feedback loops. A gap can exist between the actual quality and the actions we’re taking to improve that quality.

Representing Gaps in EHR causal loops
In our example for patient treatment quality to improve, the gap in between, as shown in the diagram, is the secure migration of the patient records from paper to digital records. This, in turn, enables more confidence to adopt and inevitably invest in the software beyond just procurement, but also designing training programs for practitioners and defining performance targets such as decreasing error rates or patient treatment time.


Cause and Effect Diagram, Onion Model Diagram and a Hierarchy
These are just a select few of the tools available in your systems utility belt. Needless to say, there’s an abundance of other ways you can visualize systems. If you’re trying to bring clarity to a post mortem, you can use a cause and effect diagram to isolate what went wrong during a project. A stock and flow diagram can help you simulate the impact of your design decisions, whereas an onion model or hierarchy can help us see top-down or bottom-up causality, and chart the flow of influence.

Each of these visual aids helps us see things we couldn’t have possibly seen through a block of text, especially when co-created with people outside our discipline. They enable us to align viewpoints, understand root causality, synthesize, generate options and even simulate design decisions within our product experiences and organizations. Quite frankly, being able to produce these artifacts is a superpower.

That superpower, however, shouldn’t go unchecked. Systems can also be consciously designed to manipulate, cheat and sometimes even harm people. This underscores our responsibility to make we have a full understanding of the chain reaction our design decisions cause beyond canvas and code.

Just like the astronauts whose new perspective of our planet engendered a new sense of responsibility for the environment, we can use whatever palette of system diagrams to shape, tug or prune systems in small but impactful increments and become catalysts for sustainable and ethical change.



